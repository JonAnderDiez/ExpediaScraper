{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAF_PDF_SCRAPER_PRODUCTION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cPAWZW6PMeg6nfIzcLpWAJ1WxPVaiI4A",
      "authorship_tag": "ABX9TyP7lhA71m38b7Ilz/Oci3Nb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonAnderDiez/ExpediaScraper/blob/master/CAF_PDF_SCRAPER_PRODUCTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNznyBXfmgVb"
      },
      "source": [
        "# CONTEXTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7yawdrwrnyy"
      },
      "source": [
        "Este scraper pretende eliminar el trabajo repetitivo de extraer líneas, bobinas, mandos, pilotos y entradas/salidas de TCMS de los esquemas que solemos utilizar en el departamento de Material para simular los trenes más nuevos (generalmente de CAF).\n",
        "\n",
        "**ACTUALMENTE YA SE PUEDE USAR** para extraer líneas que es lo más tedioso, pero dado que ya está todo preparado, resulta inmediato extraer las bobinas, pilotos, mandos, y I/Os de TCMS.\n",
        "\n",
        "Como una imagen es más útil que mil palabras:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=100BYZPQVQ3mzYKP74faBguiMTj6jvooj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4R8_skWQsEP"
      },
      "source": [
        "# TO-DO LIST\n",
        "\n",
        "<font color='green'>DONE</font> VS. <font color='orange'>WORKING</font> VS. <font color='red'>TODO</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg3y9SYXiAhI"
      },
      "source": [
        "- <font color='green'>Evitar que los desarrolladores tengan que descargar Python para usar el SCRAPER -> [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb?hl=es) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlMVOJbSSn4f"
      },
      "source": [
        "- <font color='green'> Eliminar la protección que CAF pone a los PDFs para tener derechos de escritura usando un método que no ponga en peligro la confidencialidad (open source, ejecutable en local y sin necesidad de conexión a ningún servidor) -> [Tutorial de uso](#EnlaceTutorialQuitarProteccion) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxwOHx-fdwYE"
      },
      "source": [
        "\n",
        "- <font color='red'>   Quitar la protección a los PDFs de CAF dentro del scrip sin tener que usar aplicaciones de terceros. ->  [TODO](#)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzptJNNufKjD"
      },
      "source": [
        "- <font color='green'> Extraer números de todas las **LÍNEAS** de cada esquema (se ha decidido realizar extracción por esquema y no por hoja para facilitar uso) -> [ScriptScraper](#EnlaceScriptExtraccionLineas) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_ktubefK5B"
      },
      "source": [
        "- <font color='orange'> Extraer nombre de **ELEMENTOS LISTADOS** (bobinas, mandos, diodos LED ...) de cada esquema (se ha decidido realizar extracción por esquema y no por hoja por facilitar uso) -> [ScriptScraper](#EnlaceScriptExtraccionLineas) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM88FYeflp1_"
      },
      "source": [
        "- <font color='red'>Hacer que el TrainScription lea el CSV generado con el script y que cree automáticamente los métodos de todas las líneas y todas las entradas. (Ej.: Si estamos en el esquema 111 y tenemos una línea 33111, es evidente que la línea es una entrada al esquema y por lo tanto se podría programar la \"PushEntrada\" de dicha línea mediante RegEx). ->  [TODO](#)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-7B3MYkcGC"
      },
      "source": [
        "**NOTA:** Una vez se empiece a usar, podremos comprobar el número de fallos cometidos, si el número es significativo, para hacer la aplicación más robusta se podría probar con más librerías de extracción de texto  y/o cambiando el método de quitarle la protección a los PDFs de CAF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFjVSLWUUnlk"
      },
      "source": [
        "<a name=\"EnlaceTutorialQuitarProteccion\"></a>\n",
        "# TUTORIAL DE USO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzIWcdZuU06C"
      },
      "source": [
        "1. **PDF->WORD**: Converitr PDF descargado desde VISPLAN a Word usando un programilla que he encontrado en ''C#'' : [PDF->DOCX](https://drive.google.com/file/d/1JIgF9N5pcZZo15e7hI_ePwZYxVFO5uCe/view?usp=sharing)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1epXK4HEL1bivUiHJVU72YgA225jcOk9y)\n",
        "\n",
        "**NOTA IMPORTANTE**: Es posible que la aplicación por unos segundos ponga que '(No responde)', pero siempre termina devolviendo un muy buen Word sin perder información por el camino.\n",
        "\n",
        "---\n",
        "\n",
        "2. **WORD->PDF**: En esta ocasión vamos a usar el propio Microsoft Word (o Libre Office, aunque no he probado con Libre Office). Hay que convertir el Word a PDF con un poco de cuidado para que puedan seguir leyéndose los elementos, y que no se conviertan en imágenes todas las páginas del PDF.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1LvhIz0cmDe73IA2KmwBaWNoXmum6ktDk)\n",
        "\n",
        "---\n",
        "\n",
        "3. **Guargar en Drive**: Hay que subir los PDFs resultantes a la carpeta de drive en el que se encuentre este Jupyter Notebook, copiar el código del PDF asignado en Drive, y pegarlo en el db.csv junto al nombre del PDF. Se generará un CSV por cada fila (PDF) de este db.csv.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1K6gW0LHdA7JK6Xyd7YVb-sMrdAKQfiur)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=17C8ZrBZdh3qXDjYFhNiPvRSBziSiRJ2N)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1oJpA4N8DiCCvlaML_9lWZH33VX3X3aZD)\n",
        "\n",
        "---\n",
        "\n",
        "4. **Ejecutar script**: Dado que el script lee de Drive, hay que darle permisos de la siguiente forma:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1ZOaNNkLdchsufTNokf0C6ji2mEX4WAH5)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1w29XKb8NwMOHd35Ua5sl3wmY0OKFYUJu)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1g8-8GKn2Z0Gs10Q6WtoI3XwvF3Dmf0Qn)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1GaI0mm3PA6nqlUiXkowUoldEHUil67EV)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1VHRORdeQSyIgUysnoLyfGJ8o82puE1iU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-_hoUmi-E1f"
      },
      "source": [
        "<a name=\"EnlaceScriptExtraccionLineas\"></a>\n",
        "# SCRIPT A EJECUTAR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQAt2IcDJhOZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "d9e7e025-6f22-4688-a650-7bd839f11ec9"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install PyPDF2\n",
        "\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 0 - PASAR DE STRING A LISTA DE STRINGS\n",
        "def str2lst(string): \n",
        "    li = list(string.split(\"\\n\"))\n",
        "    return li\n",
        "\n",
        "# 1 - CREAR UN OBJETO DE PDF LEYENDO ARCHIVO EN DRIVE\n",
        "def GetPDFObjFromDrive(CodigoDrive, NombrePDF):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  downloadedM = drive.CreateFile({'id': CodigoDrive})\n",
        "  downloadedM.GetContentFile(NombrePDF)\n",
        "  pdfFileObjM = open(NombrePDF, 'rb')\n",
        "  pdfReader = PyPDF2.PdfFileReader(pdfFileObjM)\n",
        "  return pdfReader\n",
        "\n",
        "# 2 - CREAR DATAFRAME CON DIMENSIONES 'ESQUEMA' Y 'HOJA'\n",
        "def GetDfEsquemaPorHoja(pdfReader):\n",
        "  ## Sacar el código de la carpeta en la que guarda CAF los esquemas eléctricos del PDF actual.\n",
        "  page = pdfReader.getPage(0)\n",
        "  page.extractText()\n",
        "  lista = (str2lst(page.extractText()))\n",
        "  df1DTexto = pd.Series(lista)\n",
        "  StringDeTextoLimpioDeEsquema = (df1DTexto[(df1DTexto.str.contains('\\w.\\w\\w.\\w\\w.\\d\\d\\d', regex=True))]).to_string()\n",
        "  strDirectorio = re.sub(r'.*(C.\\w\\w.\\w\\w.)\\d\\d\\d.*' , r'\\1' ,StringDeTextoLimpioDeEsquema) #C.J6.75.\n",
        "  # Crear intervalo de hojas que nos interesa\n",
        "  listaHojas = list(range(0, pdfReader.getNumPages()))\n",
        "  ## Crear un DataFrame con una columna que indique la \"hoja\" y otra que indique \"esquema\"\n",
        "  dfHojaEsquema = pd.DataFrame()\n",
        "  dfErroresDeLectura = pd.DataFrame()\n",
        "  for i in listaHojas:\n",
        "    page = pdfReader.getPage(i)\n",
        "    page.extractText()\n",
        "    lista = (str2lst(page.extractText()))\n",
        "    df1DTexto = pd.Series(lista)\n",
        "    StringDeTextoLimpioDeEsquema = (df1DTexto[(df1DTexto.str.contains(strDirectorio + '\\d\\d\\d', regex=True))]) + 'JDIEZ'\n",
        "    if (StringDeTextoLimpioDeEsquema.empty):\n",
        "      dfErroresDeLectura = dfErroresDeLectura.append({'hoja sin contenido': i}, ignore_index=True)\n",
        "    else:\n",
        "      StringDeTextoLimpioDeEsquema = StringDeTextoLimpioDeEsquema.head(1).item()\n",
        "      dfHojaEsquema = dfHojaEsquema.append({'hoja': (i), 'esquema': (re.sub(r'C.\\w\\w.\\w\\w.(\\d\\d\\d)JDIEZ' , r'\\1' ,StringDeTextoLimpioDeEsquema))}, ignore_index=True)\n",
        "  return dfHojaEsquema, dfErroresDeLectura\n",
        "\n",
        "# 3 - ENCONTRAR LISTA DE NÚMEROS A FILTRAR POR NO SER LÍNEAS\n",
        "def GetListaStrNumerosFake(pdfReader):\n",
        "  listaStrNumerosFake = []\n",
        "  for pag in range(0,2):\n",
        "    page = pdfReader.getPage(pag)\n",
        "    page.extractText()\n",
        "    lista = (str2lst(page.extractText()))\n",
        "    df1DTexto = pd.Series(lista)\n",
        "    dFConStringLineasSucio = (df1DTexto[(df1DTexto.str.contains('\\d\\d\\d\\d\\d', regex=True))])\n",
        "    # https://regex101.com/r/2kNe9f/1\n",
        "    for i in (dFConStringLineasSucio):\n",
        "      strLinea = re.sub(r'.*(\\d\\d\\d\\d\\d)' , r'\\1' ,i)\n",
        "      listaStrNumerosFake.append(strLinea)\n",
        "  listaStrNumerosFake = list(set(listaStrNumerosFake))\n",
        "  return listaStrNumerosFake # Ej.: ['48708', '10269', '12439', '39490', '10269', '10319']\n",
        "\n",
        "# 4 - CREAR SERIE QUE INDIQUE LAS LÍNEAS QUE HAY EN CADA HOJA\n",
        "def GetSeriesLineasFiltradasPorHoja(pdfReader, listaStrNumerosFake, NumHoja):\n",
        "  ## Crear un DataFrame con las hojas de las que queremos los IDs\n",
        "  dfHojas = pd.DataFrame()\n",
        "  page = pdfReader.getPage(NumHoja)\n",
        "  aux = (str2lst(page.extractText()))\n",
        "  dfHojas[NumHoja] = pd.Series(aux)\n",
        "  ## Data cleaning (Lineas)\n",
        "  # Todo lo que no sea un texto de 5 números lo sustituimos por un 0.\n",
        "  dfHojas_cleaned = dfHojas.replace(to_replace ='[^\\d\\d\\d\\d\\d]', value = 0, regex = True)\n",
        "  # Los NaN también los sustituimos por 0s.\n",
        "  dfHojas_cleaned = dfHojas_cleaned.fillna(0)\n",
        "  # Convertimos los datos en numericos para poder filtrarlos aprovechando la condición numérica\n",
        "  for j in (dfHojas_cleaned.columns):\n",
        "    pd.to_numeric(dfHojas_cleaned[j])\n",
        "    dfHojas_cleaned = dfHojas_cleaned.fillna(0)\n",
        "    dfHojas_cleaned[j] = pd.to_numeric(dfHojas_cleaned[j], errors='coerce', downcast='integer')\n",
        "    dfHojas_cleaned = dfHojas_cleaned.fillna(0)\n",
        "    dfHojas_cleaned[j] = dfHojas_cleaned[j].astype(int)\n",
        "  dfunified = dfHojas_cleaned.melt()['value']\n",
        "  # Filtrar IDs por comparación numérica.\n",
        "  dffiltered = dfunified[((dfunified >= 1000) & (dfunified < 100000)) | ( dfunified == 100 ) | ( dfunified == 500 ) | ( dfunified == 101 ) | ( dfunified == 501 )]\n",
        "  # Eliminar duplicados.\n",
        "  dfUnrepeated = dffiltered.drop_duplicates()\n",
        "  # Ordenar IDs de menor a mayor\n",
        "  dfSorted = dfUnrepeated.sort_values()\n",
        "  # Eliminamos excepciones de los PDFs que están contenidos en los intervalos.\n",
        "  for strNumeroFake in listaStrNumerosFake:\n",
        "      # (5) Eliminamos excepciones de los PDFs que están contenidos en los intervalos.\n",
        "      dfSorted = dfSorted[dfSorted != int(strNumeroFake)]\n",
        "  dfSorted = dfSorted.drop_duplicates()\n",
        "  return dfSorted\n",
        "\n",
        "# 5 - CREAR DATAFRAME QUE INDIQUE LAS LÍNEAS QUE HAY EN CADA ESQUEMA CON REPETICIONES\n",
        "def GetDfLineasPorEsquemaConRepeticiones(dfLineasFiltradasPorHoja, dfHojaEsquema):\n",
        "  df1 = dfLineasFiltradasPorHoja.T\n",
        "  df1 = df1.reset_index(drop=True)\n",
        "  df2 = pd.DataFrame(dfHojaEsquema['esquema'])\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "  dfLineasPorEsquema = pd.concat([df2, df1], axis=1)\n",
        "  return dfLineasPorEsquema\n",
        "\n",
        "# 6 - PROCESAR DATAFRAME QUE INDICA LAS LÍNEAS QUE HAY EN CADA ESQUEMA PARA QUE NO TENGA REPETICIONES\n",
        "def GetDfLineasPorEsquemaSinRepetir(dfLineasPorEsquema):\n",
        "  dfLineasPorEsquemaSinRepetir = pd.DataFrame()\n",
        "  UltimoEsquemaGrabado = 0\n",
        "  for esquema in dfLineasPorEsquema['esquema'].unique(): # str, ... 133 ...\n",
        "    for row in range(0,(dfLineasPorEsquema[dfLineasPorEsquema.esquema == esquema]).shape[0]): # int, desde 0 hasta número de filas del df -> dfLineasPorEsquema[dfLineasPorEsquema.esquema == esquema]\n",
        "      df = dfLineasPorEsquema[dfLineasPorEsquema.esquema == esquema]\n",
        "      df = df.reset_index(drop=True)\n",
        "      df1D = pd.DataFrame({esquema:df.loc[row, :]})\n",
        "      if (UltimoEsquemaGrabado != esquema):\n",
        "        UltimoEsquemaGrabado = esquema\n",
        "        df1D = df1D.reset_index(drop=True)\n",
        "        dfLineasPorEsquemaSinRepetir = dfLineasPorEsquemaSinRepetir.reset_index(drop=True)\n",
        "        dfLineasPorEsquemaSinRepetir = pd.concat([dfLineasPorEsquemaSinRepetir, df1D], axis=1)\n",
        "      else:\n",
        "        df1D = df1D.reset_index(drop=True)\n",
        "        dfLineasPorEsquemaSinRepetir = dfLineasPorEsquemaSinRepetir.reset_index(drop=True)\n",
        "        dfLineasPorEsquemaSinRepetir[esquema] = pd.concat([dfLineasPorEsquemaSinRepetir[esquema], df1D[1:]], axis=0, ignore_index=True)\n",
        "  return dfLineasPorEsquemaSinRepetir\n",
        "\n",
        "# 7 - DESCARGAR DF DE LÍNEAS EN UN CSV\n",
        "def DescargarCSVDfLineas(dfLineasPorEsquemaSinRepetir, strNombrePDF):\n",
        "  dfLineasPorEsquemaSinRepetir = dfLineasPorEsquemaSinRepetir.drop(index=0)\n",
        "  for i in dfLineasPorEsquemaSinRepetir.index:\n",
        "    for j in dfLineasPorEsquemaSinRepetir.columns:\n",
        "      if (math.isnan(dfLineasPorEsquemaSinRepetir[j][i]) != True): \n",
        "        dfLineasPorEsquemaSinRepetir[j][i] = int(dfLineasPorEsquemaSinRepetir[j][i])\n",
        "  dfLineasPorEsquemaSinRepetir.to_csv('LineasPorEsquema_' + strNombrePDF + '.csv', index = True)\n",
        "  files.download('LineasPorEsquema_' + strNombrePDF + '.csv')\n",
        "\n",
        "# --> PROCESAMIENTO DE UN PDF POR CADA ITERACION\n",
        "def procesoPorPDF(dbRutas, iterador):\n",
        "  # PROCESO\n",
        "  strNombrePDF = dbRutas['PDF name'][iterador]\n",
        "  CodigoDrive = dbRutas['DRIVE code'][iterador]\n",
        "  # (1) GetPDFObjFromDrive\n",
        "  pdfReader = GetPDFObjFromDrive(CodigoDrive, strNombrePDF)\n",
        "  # (2) GetDfEsquemaPorHoja\n",
        "  dfHojaEsquema, dfErroresDeLectura = GetDfEsquemaPorHoja(pdfReader)\n",
        "  # (3) GetListaStrNumerosFake\n",
        "  listaStrNumerosFake = GetListaStrNumerosFake(pdfReader)\n",
        "  # (4) GetSeriesLineasFiltradasPorHoja\n",
        "  dfLineasFiltradasPorHoja = pd.DataFrame(GetSeriesLineasFiltradasPorHoja(pdfReader, listaStrNumerosFake, int(dfHojaEsquema['hoja'][0])))\n",
        "  for NumHoja in ((dfHojaEsquema['hoja'][1:]).tolist()):\n",
        "    df1 = dfLineasFiltradasPorHoja.reset_index(drop=True)\n",
        "    df2 = GetSeriesLineasFiltradasPorHoja(pdfReader, listaStrNumerosFake, int(NumHoja)).reset_index(drop=True)\n",
        "    df2 = df2.reset_index(drop=True)\n",
        "    dfLineasFiltradasPorHoja = pd.concat([df1, df2], axis=1)\n",
        "  # (5) Relacionamos en el mismo DataFrame los esquemas con las líneas de dicho esquema\n",
        "  dfLineasPorEsquema = GetDfLineasPorEsquemaConRepeticiones(dfLineasFiltradasPorHoja, dfHojaEsquema)\n",
        "  # (6) Procesamos el DF que contine las líneas por esquema con nombres de columna repetidas para que termine habiendo nombres de columnas \n",
        "  #     sin repetir con los datos de todas las columnas que anteriormente tenían el índice repetido.\n",
        "  dfLineasPorEsquemaSinRepetir = GetDfLineasPorEsquemaSinRepetir(dfLineasPorEsquema)\n",
        "  # (7) Descargar el csv del DataFrame resultante de líneas\n",
        "  DescargarCSVDfLineas(dfLineasPorEsquemaSinRepetir, strNombrePDF)\n",
        "\n",
        "##################################\n",
        "## MAIN ##########################\n",
        "##################################\n",
        "\n",
        "# Ordenamos que se puedan mostrar muchos datos en el output del notebook\n",
        "pd.options.display.max_rows = 999\n",
        "# Datos concretos del PDF con el que vamos a trabajar.\n",
        "dfDB_rutas_Drive=pd.read_csv('/content/drive/MyDrive/DIAGRAM SCRAPER/db.csv')\n",
        "print('\\nPDFs procesados:')\n",
        "for iterador in range(0, dfDB_rutas_Drive.shape[0]):\n",
        "  procesoPorPDF(dfDB_rutas_Drive, iterador)\n",
        "  print(dfDB_rutas_Drive['PDF name'][iterador] + ' -> CSV descargable.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "PDFs procesados:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_70ba4972-f7f7-4f7a-9e02-2e0bed9c8eca\", \"LineasPorEsquema_CK8_M.csv\", 5298)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CK8_M -> CSV descargable.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_751ef918-619a-4cf0-8000-5185a38cdb3f\", \"LineasPorEsquema_CK8_TMC.csv\", 3593)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CK8_TMC -> CSV descargable.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}